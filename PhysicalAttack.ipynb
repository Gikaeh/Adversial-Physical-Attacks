{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Tutorial for Physical Attack on a white box model\n",
    "\n",
    "___\n",
    "## Contents\n",
    "1. [Prequisites](#Prerequisites)\n",
    "2. [Physical Attack Class](#Physical-Attack-Class)\n",
    "3. [GUI Setup](#gui-build-with-ipywidget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "import gdown\n",
    "gdown.download(f\"https://drive.google.com/file/d/1-07DCaJtJAlj1JdVMqtrob4d4Td7IuMw/view?usp=sharing\", 'test.keras')\n",
    "!git clone https://github.com/Gikaeh/Adversial-Physical-Attacks.git\n",
    "!mv Adversial-Physical-Attacks/* .\n",
    "!rm -rf Adversial-Physical-Attacks\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox, Layout\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm.notebook import trange\n",
    "from extra_keras_datasets import stl10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load\n",
    "Uses Tensor Flow Keras library versus standalone Keras for better cohesion. Loads previously trained and finetuned VGG16 white box model for image recognition. This model was trained on 8000 images and tested on 5000 images from CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"test.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "Define Image dimensions and class list variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class list of stl10\n",
    "class_list = [\"airplane\", \"bird\", \"car\", \"cat\", \"deer\", \"dog\", \"horse\", \"monkey\", \"ship\", \"truck\"]\n",
    "\n",
    "# image sizes\n",
    "w, h, d = 96, 96, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting images with pred. class & confidence value\n",
    "Shows the images with the models predicted class label and confidence value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, columns, rows, title, model, targets=None, gt=None, class_list= [\"airplane\", \"bird\", \"car\", \"cat\", \"deer\", \"dog\", \"horse\", \"monkey\", \"ship\", \"truck\"], w=96, h=96,d=3, size=(15, 8), ae=False):\n",
    "    fig=plt.figure(figsize=size)\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    columns = columns\n",
    "    rows = rows\n",
    "    for i in range(1, columns*rows +1):\n",
    "        img = images[i-1]\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        pred = model.predict(images[i-1].reshape(1, w, h, d))\n",
    "        pred_class = class_list[np.argmax(pred.flatten())]\n",
    "        pred_class_conf_prob = max(pred.flatten())\n",
    "        if targets is not None:\n",
    "            pred_target_class = max(pred.flatten()*targets[i-1])\n",
    "            plt.title(f\"{pred_class} ({pred_class_conf_prob:.2f})\\nTarget: {pred_target_class:.2f}\")\n",
    "        elif gt is not None:\n",
    "            plt.title(f\"{pred_class} ({pred_class_conf_prob:.2f})\\nG.T.: {gt[i-1]}\")\n",
    "        else:\n",
    "            plt.title(f\"{pred_class} ({pred_class_conf_prob:.2f})\")\n",
    "\n",
    "        if ae:\n",
    "            img = np.clip(img, 0, 1)\n",
    "\n",
    "        plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting images with mask over original\n",
    "Shows the original image with the designated mask over it. Also displaying the predicted label and confidence value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_physical_adv(model, w, h, d, adv_images, target, save=True, name=\"test\", attack_type=\"targeted\", class_list=[\"airplane\", \"bird\", \"car\", \"cat\", \"deer\", \"dog\", \"horse\", \"monkey\", \"ship\", \"truck\"]):\n",
    "    # Ensure input is iterable if single example\n",
    "    if not isinstance(adv_images, (list, np.ndarray)):\n",
    "        adv_images = [adv_images]\n",
    "\n",
    "    for i, adv_image in enumerate(adv_images):\n",
    "        # Convert tensor to numpy array if needed\n",
    "        if tf.is_tensor(adv_image):\n",
    "            adv_np = adv_image.numpy()\n",
    "        else:\n",
    "            adv_np = adv_image\n",
    "\n",
    "        # Reshape to image dimensions\n",
    "        img_array = adv_np.reshape((h, w, d))\n",
    "\n",
    "        # Make prediction\n",
    "        pred = model.predict(np.expand_dims(img_array, 0)).flatten()\n",
    "        best = np.argmax(pred)\n",
    "        target_conf = pred[np.argmax(target.flatten())]\n",
    "\n",
    "        # Save image if requested\n",
    "        if save:\n",
    "            if not os.path.isdir(\"./generated_advs\"):\n",
    "                os.mkdir(\"./generated_advs\")\n",
    "            filename = f\"./generated_advs/{name}_{class_list[best]}_{pred[best]:.2f}.jpg\"\n",
    "            plt.imsave(filename, img_array)\n",
    "\n",
    "        # Create plot\n",
    "        plt.imshow(img_array)\n",
    "        if attack_type == \"targeted\":\n",
    "            plt.title(f\"Best: {class_list[best]} ({pred[best]:.2f})\\nTarget: {target_conf:.2f}\")\n",
    "        else:\n",
    "            plt.title(f\"Best: {class_list[best]} ({pred[best]:.2f}\\nG.T.: {target_conf:.2f})\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "Evaluate white box model on set of nine images using the plot_images function mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get attack images\n",
    "org_images = []\n",
    "for path in os.listdir(\"./physical_attack_data/imgs_gui/\"):\n",
    "    img = plt.imread(\"./physical_attack_data/imgs_gui/\" + path)\n",
    "    org_images.append(img/255.)\n",
    "org_images = np.array(org_images) \n",
    "plot_images(org_images, 3, 3, title=\"Original Images\", model=model, size=(10, 11))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical Attack Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     6,
     48,
     61,
     68,
     145
    ]
   },
   "outputs": [],
   "source": [
    "class PhysicalAttack():\n",
    "    def __init__(self, img_rows, img_cols, depth, n_classes, noisy_input_clip_min, noisy_input_clip_max, attack_lambda, print_lambda, lr, model, targeted):\n",
    "        # Input dimensions\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.depth = depth # Color channels\n",
    "        self.n_classes = n_classes # number of output classes\n",
    "\n",
    "        # Clipping bounds\n",
    "        self.noisy_input_clip_min = noisy_input_clip_min\n",
    "        self.noisy_input_clip_max = noisy_input_clip_max\n",
    "\n",
    "        # Loss weights\n",
    "        self.attack_lambda = attack_lambda # Weight for regularization loss\n",
    "        self.print_lambda = print_lambda # Weight for printable color loss\n",
    "\n",
    "        # Optimization\n",
    "        self.lr = lr\n",
    "        self.opt = tf.keras.optimizers.Adam(learning_rate=lr, epsilon=1e-08)\n",
    "        \n",
    "        # Model and mode\n",
    "        self.model = model\n",
    "        self.targeted = targeted # Targeted: Specific incorrect prediction; Untargeted: Any missclassification\n",
    "\n",
    "        # Noise variable (trainable)\n",
    "        self.noise = tf.Variable(\n",
    "            tf.random.uniform([img_rows, img_cols, depth], 0.0, 1.0), # Random noise with a min of 0 and max of 1\n",
    "            trainable=True, # Optimized noise during training\n",
    "            name='noise'\n",
    "        )\n",
    "\n",
    "        # Define input signatures for tf.function\n",
    "        self.train_step = tf.function(\n",
    "            self._train_step, # Compile training step during class initialization\n",
    "            input_signature=[\n",
    "                tf.TensorSpec(shape=(None, img_rows, img_cols, depth), dtype=tf.float32), # Input Image\n",
    "                tf.TensorSpec(shape=(None, n_classes), dtype=tf.float32), # Labels\n",
    "                tf.TensorSpec(shape=(img_rows, img_cols, depth), dtype=tf.float32), # Noise mask\n",
    "                tf.TensorSpec(shape=(None, img_rows, img_cols, depth), dtype=tf.float32), # Printable colors\n",
    "                tf.TensorSpec(shape=(), dtype=tf.float32), # Min clip\n",
    "                tf.TensorSpec(shape=(), dtype=tf.float32), # Max clip\n",
    "                tf.TensorSpec(shape=(), dtype=tf.float32), # Attack lamba\n",
    "                tf.TensorSpec(shape=(), dtype=tf.float32) # Print lambda\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _l1_norm(self, tensor):\n",
    "        # Computes L1 regularization loss\n",
    "        return tf.reduce_sum(tf.abs(tensor))\n",
    "\n",
    "    def _train_step(self, image_in, attack_target, noise_mask, printable_colors, noisy_input_clip_min, noisy_input_clip_max, attack_lambda, print_lambda):\n",
    "      with tf.GradientTape() as tape:\n",
    "          # Forward pass\n",
    "          noise_mul = tf.multiply(noise_mask, self.noise) # Apply mask to noise\n",
    "          noise_mul_clip = tf.clip_by_value(noise_mul, noisy_input_clip_min, noisy_input_clip_max) # Clip noise\n",
    "          inverse_masks = 1.0 - noise_mask\n",
    "          # Combine image and noise\n",
    "          noise_inputs = tf.clip_by_value(\n",
    "              tf.add(image_in * inverse_masks, noise_mul), # Add mask img to mask perturbation\n",
    "              noisy_input_clip_min, noisy_input_clip_max\n",
    "          )\n",
    "\n",
    "          # Model predictions\n",
    "          adv_pred = self.model(noise_inputs)\n",
    "\n",
    "          # Regularization loss\n",
    "          reg_loss = self._l1_norm(noise_mul)\n",
    "\n",
    "          # Classification loss\n",
    "          loss_f = tf.keras.losses.categorical_crossentropy(attack_target, adv_pred, from_logits=False)\n",
    "          loss = tf.cond(\n",
    "              tf.logical_not(self.targeted), # If untargeted, minimize confidence in true class\n",
    "              lambda: 1/(loss_f + 1e-3), # Inverse loss for untargeted 1/(CE+(1e-3))\n",
    "              lambda: loss_f # Direct loss for targeted\n",
    "          )\n",
    "\n",
    "          # Printable color loss\n",
    "          printab_diff = tf.math.squared_difference(noise_mul, printable_colors * noise_mask) #Difference from printable colors\n",
    "          printer_error = tf.reduce_sum(tf.reduce_prod(tf.reduce_sum(printab_diff, 3), 0))\n",
    "\n",
    "          # Total adversarial loss\n",
    "          adv_loss = loss + attack_lambda * reg_loss + print_lambda * printer_error\n",
    "\n",
    "      # Gradient calculation & application\n",
    "      grads = tape.gradient(adv_loss, [self.noise])\n",
    "      self.opt.apply_gradients(zip(grads, [self.noise]))\n",
    "\n",
    "      return [adv_loss, noise_inputs, loss, reg_loss, printer_error, noise_mul_clip, loss_f]\n",
    "\n",
    "    def generate(self, n_epochs, img, target, mask, print_colors, verbose=True):\n",
    "      # Initialize noise\n",
    "      self.noise.assign(tf.random.uniform(self.noise.shape, 0.0, 1.0))\n",
    "\n",
    "      for i in (trange(n_epochs) if verbose else range(n_epochs)):\n",
    "          outputs = self.train_step(\n",
    "              img, target, mask, print_colors,\n",
    "              self.noisy_input_clip_min, self.noisy_input_clip_max,\n",
    "              self.attack_lambda, self.print_lambda\n",
    "          )\n",
    "\n",
    "          if verbose and (i % 200 == 0):\n",
    "              adv_loss, _, loss_cat, _, loss_print, clipped_noise, _ = outputs\n",
    "              print(f\"\\nEpoch {i}: Total Loss: {float(adv_loss):.4f}, \"\n",
    "                    f\"Classification Loss: {float(loss_cat):.4f}, \"\n",
    "                    f\"Print Loss: {float(loss_print):.4f}\")\n",
    "              plt.imshow(clipped_noise.numpy().reshape(self.img_rows, self.img_cols, 3))\n",
    "              plt.show()\n",
    "\n",
    "      return outputs[1]  # Return noise_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eager Execution Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicalAttack:\n",
    "    \"\"\"\n",
    "    This class implements a physical attack.\n",
    "    During the attack, the noise is optimized within a certain mask in a way that the attack is successful.\n",
    "    To make the attack potentially printable, colors for the noise can be set.\n",
    "    \"\"\"\n",
    "    def __init__(self, img_rows, img_cols, depth, n_classes, noisy_input_clip_min, noisy_input_clip_max, attack_lambda, print_lambda, lr, model, targeted):\n",
    "\n",
    "        # Input image data\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.depth = depth\n",
    "\n",
    "        # This class is optimized for stl10 dataset\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        # Clip the noise between 0 and 1 (for images)\n",
    "        self.noisy_input_clip_min = noisy_input_clip_min\n",
    "        self.noisy_input_clip_max = noisy_input_clip_max\n",
    "\n",
    "        # Regularization loss for the noise. Currently not used (is 0)\n",
    "        self.attack_lambda = attack_lambda\n",
    "\n",
    "        # Loss weight for the printable colors\n",
    "        self.print_lambda = print_lambda\n",
    "\n",
    "        # Learning rate\n",
    "        self.lr = lr\n",
    "\n",
    "        # Model we want to attack\n",
    "        self.model = model\n",
    "\n",
    "        # Variable for the noise\n",
    "        self.noise = tf.Variable(tf.random.uniform([img_rows, img_cols, depth], 0.0, 1.0), trainable=True)\n",
    "\n",
    "        # Boolean, true if we want a targeted attack\n",
    "        self.targeted = targeted\n",
    "\n",
    "        # Set allowed params, which the user can modify\n",
    "        self.attack_params = list(self.__dict__.keys())\n",
    "\n",
    "        # Define the optimizer\n",
    "        self.opt = tf.keras.optimizers.Adam(learning_rate=self.lr, epsilon=1e-08)\n",
    "\n",
    "    def set_params(self, **kwargs):\n",
    "        \"\"\"\n",
    "        This method sets the allowed attributes\n",
    "        \"\"\"\n",
    "        for key, value in kwargs.items():\n",
    "            if key in self.attack_params:\n",
    "                setattr(self, key, value)\n",
    "                print(key, value)\n",
    "            else:\n",
    "                raise KeyError(\"Unknown property \", key)\n",
    "        return True\n",
    "\n",
    "    def _l1_norm(self, tensor):\n",
    "        \"\"\"\n",
    "        This method calculates the l1 norm\n",
    "        :param tensor masked noise\n",
    "        \"\"\"\n",
    "        return tf.reduce_sum(tf.abs(tensor))\n",
    "\n",
    "    def train_step(self, image_in, attack_target, noise_mask, printable_colors):\n",
    "        \"\"\"\n",
    "        Perform one training step in eager execution mode.\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Multiply noise with mask\n",
    "            noise_mul = tf.multiply(noise_mask, self.noise)\n",
    "\n",
    "            # Clip noise_mul for printing\n",
    "            noise_mul_clip = tf.clip_by_value(noise_mul, self.noisy_input_clip_min, self.noisy_input_clip_max)\n",
    "\n",
    "            # Get the inverse mask, build the sum of masked noise + inverse masked image\n",
    "            inverse_masks = 1.0 - noise_mask\n",
    "            noise_inputs = tf.clip_by_value(tf.add(image_in * inverse_masks, noise_mul),\n",
    "                                            self.noisy_input_clip_min, self.noisy_input_clip_max)\n",
    "\n",
    "            # Get the prediction of the white box for the current noise\n",
    "            adv_pred = self.model(noise_inputs)\n",
    "\n",
    "            # Regularization loss\n",
    "            reg_loss = self._l1_norm(noise_mul)\n",
    "\n",
    "            # Classification loss\n",
    "            loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "            loss_f = loss_function(attack_target, adv_pred)\n",
    "            \n",
    "            # If targeted is false, than attack_target holds the g.t., therefore take loss inverse\n",
    "            if not self.targeted:\n",
    "                # Adding small amount to avoid division by zero\n",
    "                loss = 1 / (loss_f + 1e-3)\n",
    "            else:\n",
    "                loss = loss_f\n",
    "\n",
    "            ####\n",
    "            # PRINTABILITY LOSS\n",
    "            ####\n",
    "            printab_pixel_element_diff = tf.squared_difference(noise_mul, printable_colors * noise_mask)\n",
    "            printab_pixel_diff = tf.reduce_sum(printab_pixel_element_diff, 3)\n",
    "            printab_reduce_prod = tf.reduce_prod(printab_pixel_diff, 0)\n",
    "            printer_error = tf.reduce_sum(printab_reduce_prod)\n",
    "\n",
    "            ####\n",
    "            # ADV LOSS\n",
    "            ####\n",
    "            adv_loss = loss + self.attack_lambda * reg_loss + self.print_lambda * printer_error\n",
    "\n",
    "        # Compute gradients of the adversarial loss with respect to the noise variable\n",
    "        gradients = tape.gradient(adv_loss, [self.noise])\n",
    "\n",
    "        # Apply the gradients to update the noise variable\n",
    "        self.opt.apply_gradients(zip(gradients, [self.noise]))\n",
    "\n",
    "        return adv_loss, noise_inputs, loss, reg_loss, printer_error, noise_mul_clip, loss_f\n",
    "\n",
    "    def generate(self, n_epochs, img, target, mask, print_colors, verbose=True):\n",
    "        \"\"\"\n",
    "        This method starts the attack\n",
    "        :param n_epochs     Define the number of epochs we want to optimize the noise\n",
    "        :param img          Attack image\n",
    "        :param target       Target list. If targeted is false, this holds the g.t.\n",
    "        :param mask         Images of the masks\n",
    "        :param print_colors Images containing the allowed colors\n",
    "\n",
    "        :return noisy_input The final output of the attack. This is the attack image + noise\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            # Optimize noise over n_epochs\n",
    "            for i in trange(n_epochs):\n",
    "                # Do one step\n",
    "                loss_all, noisy_input, loss_cat, loss_reg, loss_print, clipped_noise, losses_f = self.train_step(\n",
    "                    img, target, mask, print_colors)\n",
    "\n",
    "                if i % 200 == 0:\n",
    "                    print()\n",
    "                    print(f\"loss all {loss_all}, loss prediction: {loss_cat}, loss printer: {loss_print}\")\n",
    "                    plt.title(\"Current Noise\")\n",
    "                    plt.imshow(clipped_noise.numpy().reshape(96, 96, 3))\n",
    "                    plt.show()\n",
    "        else:\n",
    "            # Optimize noise over n_epochs\n",
    "            for i in range(n_epochs):\n",
    "                # Do one step\n",
    "                loss_all, noisy_input, loss_cat, loss_reg, loss_print, clipped_noise, losses_f = self.train_step(\n",
    "                    img, target, mask, print_colors)\n",
    "\n",
    "        return noisy_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gui Build with Ipywidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0,
     7,
     18,
     32,
     43,
     75
    ]
   },
   "outputs": [],
   "source": [
    "def row(descr):\n",
    "    \"\"\"\n",
    "    This is used to create images and checkboxes next to each other\n",
    "    \"\"\"\n",
    "    return widgets.Checkbox(description=descr, value=False, indent=False)\n",
    "\n",
    "\n",
    "def img_checkbox_listener(change):\n",
    "    \"\"\"\n",
    "    This method manually allows only one checkbox to be checked.\n",
    "    :param change    dictionary with changes\n",
    "    \"\"\"\n",
    "    curr_descr = change[\"owner\"].description\n",
    "    for rb in rbs_imgs:\n",
    "        if rb.description != curr_descr:\n",
    "            rb.value=False\n",
    "            \n",
    "            \n",
    "def printer_loss_listener(change):\n",
    "    \"\"\"\n",
    "    This listener enables or disbables the printer hyperparameters \n",
    "    if we don't want to include printable colors\n",
    "    :param change    dictionary with changes\n",
    "    \"\"\"\n",
    "    if change[\"new\"] == \"Enable\":\n",
    "        colors.disabled=False\n",
    "        print_lambda_slider.disabled = False\n",
    "    elif  change[\"new\"] == \"Disable\":\n",
    "        colors.disabled=True\n",
    "        print_lambda_slider.disabled = True\n",
    "\n",
    "\n",
    "def attack_type_listener(change):\n",
    "    \"\"\"\n",
    "    This listener enables or disbables the target selection\n",
    "    :param change    dictionary with changes\n",
    "    \"\"\"\n",
    "    if change[\"new\"] == \"untargeted\":\n",
    "        targets.disabled=True\n",
    "    elif  change[\"new\"] == \"targeted\":\n",
    "        targets.disabled=False\n",
    "\n",
    "\n",
    "def _read_img(descr_list, is_mask, w, h, d):\n",
    "    \"\"\"\n",
    "    This method is used to read in attack images or masks\n",
    "    :param descr_list    list of html descriptions of images\n",
    "    :param is_mask       true, if image is a mask\n",
    "    :param w             width of image\n",
    "    :param h             height if image\n",
    "    :param d             depth of image\n",
    "    \"\"\"\n",
    "    \n",
    "    # descriptions look like <img src='...'>. We extract the image path\n",
    "    pattern = re.compile(r\"'(.*?)'\")\n",
    "    \n",
    "    # check if image is a mask\n",
    "    if is_mask:\n",
    "        masks = []\n",
    "        # load all masks \n",
    "        for m in descr_list:\n",
    "            path = re.findall(pattern, m)[0]\n",
    "            mask = cv2.imread(path)\n",
    "            mask = mask/255.\n",
    "            masks.append(mask)\n",
    "        return masks\n",
    "    else:    \n",
    "        # load attack image\n",
    "        path = re.findall(pattern, descr_list[0])[0]\n",
    "        img = plt.imread(path)\n",
    "        img = img/255.\n",
    "        img = img.reshape(1, w, h, d)\n",
    "        return img, path\n",
    "\n",
    "\n",
    "def _load_color_list(colors_str, w, h):\n",
    "    \"\"\"\n",
    "    Load the printable colors and convert them into images with w, h, (d).\n",
    "    For each color an image is generated that only contains pixel with that color\n",
    "    :param colors_str       Textarea from the gui, containing the defined colors\n",
    "    :param w                width of image\n",
    "    :param h                height of image\n",
    "    \n",
    "    :return p               colored images\n",
    "    \"\"\"\n",
    "    \n",
    "    # container for colored images\n",
    "    p = []\n",
    "    \n",
    "    # iterate over each color in the string\n",
    "    for c in colors_str.split(\"\\n\"):\n",
    "        p.append(c.split(\",\"))       \n",
    "    \n",
    "    # generate w, h, d images\n",
    "    p = map(lambda x: [[x for _ in range(w)] for __ in range(h)], p)\n",
    "    p = np.array(list(p)).astype(float)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     4,
     10,
     16,
     26,
     33,
     40,
     49,
     57,
     65,
     73,
     81,
     88,
     97,
     105
    ]
   },
   "outputs": [],
   "source": [
    "####\n",
    "# Create checkboxes for the input images\n",
    "# We set 9 images fix from stl10 dataset\n",
    "####\n",
    "rbs_imgs = (row(\"<img src='physical_attack_data/imgs_gui/airplane.jpg'>\"), row(\"<img src='physical_attack_data/imgs_gui/bird.jpg'>\"), \n",
    "            row(\"<img src='physical_attack_data/imgs_gui/car.jpg'>\"), row(\"<img src='physical_attack_data/imgs_gui/cat.jpg'>\"), \n",
    "            row(\"<img src='physical_attack_data/imgs_gui/deer.jpg'>\"), row(\"<img src='physical_attack_data/imgs_gui/dog.jpg'>\"),\n",
    "            row(\"<img src='physical_attack_data/imgs_gui/horse.jpg'>\"), row(\"<img src='physical_attack_data/imgs_gui/monkey.jpg'>\"),\n",
    "            row(\"<img src='physical_attack_data/imgs_gui/ship.jpg'>\"))   \n",
    "radio_buttons_imgs = widgets.HBox([*rbs_imgs], layout=Layout(height=\"300px\", width='100%', display='inline-flex',flex_flow='row wrap')) \n",
    "for rb in rbs_imgs:\n",
    "    rb.observe(img_checkbox_listener)\n",
    "\n",
    "    \n",
    "# Create GUI elements\n",
    "# Create checkboxes for the masks\n",
    "####\n",
    "rbs = ( row(\"<img src='physical_attack_data/masks/mask1.png'>\"), row(\"<img src='physical_attack_data/masks/mask2.png'>\"), \n",
    "        row(\"<img src='physical_attack_data/masks/mask3.png'>\"), row(\"<img src='physical_attack_data/masks/mask4.png'>\"), \n",
    "        row(\"<img src='physical_attack_data/masks/mask5.png'>\"), row(\"<img src='physical_attack_data/masks/mask6.png'>\"))\n",
    "radio_buttons = widgets.HBox([*rbs], layout=Layout(height=\"300px\", width='100%', display='inline-flex',flex_flow='row wrap'))\n",
    "\n",
    "\n",
    "####\n",
    "# Create widgets for hyperparametrs\n",
    "####\n",
    "# width of image (currently fixed to stl10)\n",
    "w_input = widgets.Text(\n",
    "    value='96',\n",
    "    description='Input width:',\n",
    "    style ={'description_width': '150px'},\n",
    "    disabled=True\n",
    ")\n",
    "# height of image (currently fixed to stl10)\n",
    "h_input = widgets.Text(\n",
    "    value='96',\n",
    "    description='Input height:',\n",
    "    style ={'description_width': '150px'},\n",
    "    disabled=True\n",
    ")\n",
    "# depth of image (currently fixed to stl10)\n",
    "d_input = widgets.Text(\n",
    "    value='3',\n",
    "    description='Input depth:',\n",
    "    style ={'description_width': '150px'},\n",
    "    disabled=True\n",
    ")\n",
    "input_dims = HBox([w_input, h_input, d_input])\n",
    "\n",
    "# number of classes in stl10\n",
    "n_classes = widgets.Text(\n",
    "    value='10',\n",
    "    description='Number of classes:',\n",
    "    style ={'description_width': '150px'},\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "# number of epochs slider\n",
    "n_epochs = widgets.IntSlider(\n",
    "    value=1000,\n",
    "    min=100, max=2000, step=100,\n",
    "    description='Number Epochs:',\n",
    "    style ={'description_width': '150px', 'width':'100%'}\n",
    ")\n",
    "\n",
    "# printer loss slider\n",
    "print_lambda_slider = widgets.FloatSlider(\n",
    "    value=0.01,\n",
    "    min=0, max=1, step=0.01,\n",
    "    description='Printer Lambda:',\n",
    "    style ={'description_width': '150px', 'width':'100%'}\n",
    ")\n",
    "\n",
    "# learning rate slider\n",
    "lr = widgets.FloatSlider(\n",
    "    value=0.1,\n",
    "    min=0.01, max=0.1, step=0.01,\n",
    "    description='Learning Rate:',\n",
    "    style ={'description_width': '150px'}\n",
    ")\n",
    "\n",
    "# printable colors textarea\n",
    "colors = widgets.Textarea(\n",
    "    value='0.01, 0.01, 0.01\\n1, 1, 1',\n",
    "    description='Color List:',\n",
    "    style ={'description_width': '150px'}\n",
    ")\n",
    "\n",
    "# attack type radio button\n",
    "attack_type = widgets.RadioButtons(\n",
    "    options=['targeted', 'untargeted'],\n",
    "    description='Attack type:',\n",
    "    disabled=False,\n",
    "    style ={'description_width': '150px'}\n",
    ")\n",
    "attack_type.observe(attack_type_listener)\n",
    "\n",
    "# targets radio buttons\n",
    "targets = widgets.RadioButtons(\n",
    "    options=class_list,\n",
    "    description=\"Targets\",\n",
    "    disabled=False,\n",
    "    style ={'description_width': '150px'}\n",
    ")\n",
    "\n",
    "# print attack boolean radio button\n",
    "printer_attack = widgets.RadioButtons(\n",
    "    options=['Enable', 'Disable'],\n",
    "    description='Print Loss',\n",
    "    disabled=False,\n",
    "    style ={'description_width': '150px'}\n",
    ")\n",
    "printer_attack.observe(printer_loss_listener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def attack_button_listener(btn_object):\n",
    "    \"\"\"\n",
    "    This method is the starting point of the attack. It gets triggered as soon as the user clicks on the attack button\n",
    "    \"\"\"\n",
    "    print(\"Starting the attack...\")\n",
    "\n",
    "    # get attack image description\n",
    "    selected_imgs = []\n",
    "    for i, item in enumerate(rbs_imgs):\n",
    "        if item.value:\n",
    "            selected_imgs.append(item.description)\n",
    "\n",
    "    # user needs to select one image\n",
    "    if len(selected_imgs) == 0:\n",
    "        print(\"Please select at least one image\")\n",
    "    else:\n",
    "        # read in image\n",
    "        img, path = _read_img(selected_imgs, False, int(w_input.value), int(h_input.value), int(d_input.value))\n",
    "\n",
    "        # true label is encoded inside the file name\n",
    "        path = path.split(\"/\")[2]\n",
    "        true_label = path.split(\".\")[0]\n",
    "        # true_label = os.path.splitext(path)[0]\n",
    "\n",
    "        # get masks descriptions\n",
    "        selected_masks = []\n",
    "        for i, item in enumerate(rbs):\n",
    "            if item.value:\n",
    "                selected_masks.append(item.description)\n",
    "\n",
    "        # user needs to select at least one mask\n",
    "        if len(selected_masks) == 0:\n",
    "            print(\"Please select at least one mask\")\n",
    "        else:\n",
    "            #read in mask\n",
    "            masks = _read_img(selected_masks, True, int(w_input.value), int(h_input.value), int(d_input.value))\n",
    "\n",
    "            # generate target vectors\n",
    "            target = np.zeros((1, len(class_list)))\n",
    "\n",
    "            # if targeted attack, then take the user defined target\n",
    "            # else take the g.t. as target\n",
    "            if attack_type.value == \"targeted\":\n",
    "                target[0][class_list.index(targets.value)] = 1\n",
    "            else:\n",
    "                target[0][class_list.index(true_label)] = 1\n",
    "\n",
    "            # this is our white box model\n",
    "            model = tf.keras.models.load_model(\"test.keras\")\n",
    "\n",
    "            # load the printable colors\n",
    "            p = _load_color_list(colors.value, int(w_input.value), int(h_input.value))\n",
    "\n",
    "            # check if we want to include colors inside the attack\n",
    "            print_lambda = 0\n",
    "            if printer_attack.value == \"Enable\":\n",
    "                print_lambda =  print_lambda_slider.value\n",
    "\n",
    "            ####\n",
    "            # Instatiate the PhysicalAttack class and set parameter\n",
    "            # Attack lambda is set to zero, because we don't care about how much we see the noise\n",
    "            ####\n",
    "            attack = PhysicalAttack(img_rows=int(h_input.value),\n",
    "                                    img_cols=int(w_input.value),\n",
    "                                    depth=int(d_input.value),\n",
    "                                    n_classes=int(n_classes.value),\n",
    "                                    noisy_input_clip_min = 0,\n",
    "                                    noisy_input_clip_max = 1,\n",
    "                                    attack_lambda = 0,\n",
    "                                    print_lambda = float(print_lambda),\n",
    "                                    lr = float(lr.value),\n",
    "                                    model=model,\n",
    "                                    targeted = attack_type.value == \"targeted\")\n",
    "\n",
    "            # container for generated images\n",
    "            adv_images = []\n",
    "            for i, m in enumerate(masks):\n",
    "                print(f\"Mask {i+1}\", \"#\"*20)\n",
    "                # do the attack of n_epochs for each mask\n",
    "                adv_images.append(attack.generate(img=img,\n",
    "                                            n_epochs=int(n_epochs.value),\n",
    "                                            target=target,\n",
    "                                            mask=m,\n",
    "                                            print_colors=p,\n",
    "                                            verbose=1))\n",
    "            # plot all generated images\n",
    "            plot_physical_adv(model, int(w_input.value), int(h_input.value), int(d_input.value),\n",
    "                              adv_images, target, save=True, name=true_label, attack_type=attack_type.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create attack button and listen to it with the above function\n",
    "button = widgets.Button(\n",
    "    description='Run Attack',\n",
    ")\n",
    "button.on_click(attack_button_listener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build gui\n",
    "tab_rb_imgs = VBox(children=[radio_buttons_imgs])\n",
    "tab_rb = VBox(children=[radio_buttons])\n",
    "tab_hp = VBox(children=[input_dims,\n",
    "                        \n",
    "                      attack_type,\n",
    "                        targets,\n",
    "                        n_epochs,\n",
    "                        lr,\n",
    "                        printer_attack,\n",
    "                        colors,\n",
    "                       print_lambda_slider\n",
    "                       \n",
    "                       ])\n",
    "\n",
    "gui = widgets.Tab(children=[ tab_rb_imgs, tab_rb, tab_hp])\n",
    "gui.set_title(0, 'Choose Image')\n",
    "gui.set_title(1, 'Choose Masks')\n",
    "gui.set_title(2, 'Hyperparameter')\n",
    "VBox(children=[gui, button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# define stl10 class list and preprocess dataset\n",
    "class_list = [\"airplane\", \"bird\", \"car\", \"cat\", \"deer\", \"dog\", \"horse\", \"monkey\", \"ship\", \"truck\"]\n",
    "num_classes = 10\n",
    "\n",
    "# define width, height and dimension of images\n",
    "w, h, d = 96, 96, 3\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_test, y_test), (x_train, y_train)= stl10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "# Stl10 datasets starts with class 1, not 0\n",
    "y_train = keras.utils.to_categorical(y_train-1, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test-1, num_classes)\n",
    "\n",
    "# Scale data between 0 and 1\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# number of images included in the validation\n",
    "number_of_images = 100\n",
    "\n",
    "# Instatiate attack class and read in masks\n",
    "# define the class\n",
    "attack = PhysicalAttack(img_rows=96,\n",
    "                        img_cols=96,\n",
    "                        depth=3,\n",
    "                        n_classes=10,\n",
    "                        noisy_input_clip_min = 0,\n",
    "                        noisy_input_clip_max = 1,\n",
    "                        attack_lambda = 0,\n",
    "                        print_lambda = 0,\n",
    "                        lr = 0.1,\n",
    "                        model=model,\n",
    "                        targeted = False)\n",
    "\n",
    "# load the masks\n",
    "masks = []\n",
    "mask_paths = [\"./physical_attack_data/masks/mask1.png\", \"./physical_attack_data/masks/mask2.png\", \"./physical_attack_data/masks/mask3.png\"]\n",
    "for m_path in mask_paths:    \n",
    "    mask = cv2.imread(m_path)\n",
    "    mask = mask/255.\n",
    "    masks.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Attack the Images, this takes long for 2000 images!\n",
    "if not os.path.isfile(f\"physical_attack_data/pickle_dumps/adv_on_{number_of_images}.p\"):\n",
    "    if not os.path.isdir(f\"physical_attack_data/pickle_dumps\"):\n",
    "        os.mkdir(\"physical_attack_data/pickle_dumps\")\n",
    "    # storage for all adv images\n",
    "    all_advs = []\n",
    "    # dummy colors\n",
    "    with tf.device('/GPU:0'):\n",
    "        p = _load_color_list(\"1, 1, 1\", int(w_input.value), int(h_input.value)) \n",
    "        for i in trange(len(x_test[:number_of_images])):\n",
    "            t_image = x_test[i]\n",
    "            adv_images = []\n",
    "            for j, m in enumerate(masks):\n",
    "                # do the attack of n_epochs for each mask\n",
    "                adv_images.append(attack.generate(img=t_image.reshape(1, 96, 96, 3), \n",
    "                                            n_epochs=400, \n",
    "                                            target=y_test[i:i+1], \n",
    "                                            mask=m, \n",
    "                                            print_colors=p, \n",
    "                                            verbose=0))\n",
    "            all_advs.append(adv_images)\n",
    "\n",
    "        # dump the results    \n",
    "        all_advs = np.array(all_advs)\n",
    "        pickle.dump( all_advs, open( f\"physical_attack_data/pickle_dumps/adv_on_{number_of_images}.p\", \"wb\" ))\n",
    "        print(f\"Dump new adversarial images\")\n",
    "else:\n",
    "    all_advs = pickle.load(open( f\"physical_attack_data/pickle_dumps/adv_on_{number_of_images}.p\", \"rb\" ))\n",
    "    print(\"Load existing dump of adversarial images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Baseline of first {number_of_images} images: \", model.evaluate(x_test[:number_of_images], y_test[:number_of_images])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_advs.shape)\n",
    "\n",
    "# first extract images per mask and do reshape\n",
    "all_advs = np.array(all_advs)\n",
    "first_masks = all_advs[:, 0].reshape(-1, 96, 96, 3)\n",
    "second_masks = all_advs[:, 1].reshape(-1, 96, 96, 3)\n",
    "third_masks = all_advs[:, 2].reshape(-1, 96, 96, 3)\n",
    "\n",
    "# check model acc, success rate is 1-model acc\n",
    "print(\"Succes rate of mask 1: \", 1- model.evaluate(first_masks, y_test[:number_of_images])[1])\n",
    "print(\"Succes rate of mask 2: \", 1- model.evaluate(second_masks, y_test[:number_of_images])[1])\n",
    "print(\"Succes rate of mask 3: \", 1- model.evaluate(third_masks, y_test[:number_of_images])[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Mask    | Attack Type  | Printer Loss | Success rate (%)  | #Images\n",
    "|---|---|---|---|---|\n",
    "| Mask1  | untargeted  | disabled| 94.7  | 2000|\n",
    "| Mask2  |  untargeted | disabled| 57.8 |2000|\n",
    "| Mask3  | untargeted  | disabled |59.8 |  2000| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_images(first_masks[20:30], 5, 2, title=\"Examples First Mask\", model=model, size=(10, 5))\n",
    "plot_images(second_masks[60:70], 5, 2, title=\"Examples Second Mask\", model=model, size=(10, 5))\n",
    "plot_images(third_masks[90:100], 5, 2, title=\"Examples Third Mask\", model=model, size=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load digital and printed images\n",
    "# original digital image\n",
    "img_org = plt.imread(\"./physical_attack_data/imgs_adv/deer.jpg\")\n",
    "img_org = img_org/255.\n",
    "\n",
    "# original attack image\n",
    "attack_org = plt.imread(\"./physical_attack_data/imgs_adv/deer_airplane.jpg\")\n",
    "attack_org = attack_org/255.\n",
    "\n",
    "# photo original image\n",
    "img_photo = plt.imread(\"./physical_attack_data/imgs_adv/deer_org.jpg\")\n",
    "img_photo = img_photo/255.\n",
    "\n",
    "\n",
    "# photo attack image\n",
    "attack_photo = plt.imread(\"./physical_attack_data/imgs_adv/deer_adv.jpg\")\n",
    "attack_photo = attack_photo/255.\n",
    "\n",
    "\n",
    "plot_images(np.array([img_org, attack_org, img_photo, attack_photo]), columns=2, rows=2, model=model, title=\"Deer Example (Success)\", size=(15, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load digital and printed images\n",
    "# original digital image\n",
    "img_org = plt.imread(\"./physical_attack_data/imgs_adv/airplane.jpg\")\n",
    "img_org = img_org/255.\n",
    "\n",
    "# original attack image\n",
    "attack_org = plt.imread(\"./physical_attack_data/imgs_adv/airplane_ship.jpg\")\n",
    "attack_org = attack_org/255.\n",
    "\n",
    "# photo original image\n",
    "img_photo = plt.imread(\"./physical_attack_data/imgs_adv/airplane_org.jpg\")\n",
    "img_photo = img_photo/255.\n",
    "\n",
    "\n",
    "# photo attack image\n",
    "attack_photo = plt.imread(\"./physical_attack_data/imgs_adv/airplane_adv_ship.jpg\")\n",
    "attack_photo = attack_photo/255.\n",
    "\n",
    "\n",
    "plot_images(np.array([img_org, attack_org, img_photo, attack_photo]), columns=2, rows=2, model=model, title=\"Airplane untargeted (Success)\", size=(15, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load digital and printed images\n",
    "# original digital image\n",
    "img_org = plt.imread(\"./physical_attack_data/imgs_adv/airplane.jpg\")\n",
    "img_org = img_org/255.\n",
    "\n",
    "# original attack image\n",
    "attack_org = plt.imread(\"./physical_attack_data/imgs_adv/airplane_horse.jpg\")\n",
    "attack_org = attack_org/255.\n",
    "\n",
    "# photo original image\n",
    "img_photo = plt.imread(\"./physical_attack_data/imgs_adv/airplane_org.jpg\")\n",
    "img_photo = img_photo/255.\n",
    "\n",
    "\n",
    "# photo attack image\n",
    "attack_photo = plt.imread(\"./physical_attack_data/imgs_adv/airplane_adv_horse.jpg\")\n",
    "attack_photo = attack_photo/255.\n",
    "\n",
    "\n",
    "plot_images(np.array([img_org, attack_org, img_photo, attack_photo]), columns=2, rows=2, model=model, title=\"Airplane targeted (Failure)\", size=(15, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Sources\n",
    "[1] [Robust Physical-World Attacks on Machine Learning Models](https://arxiv.org/abs/1707.08945)  \n",
    "[2] [Accessorize to a Crime: Real and Stealthy Attacks on\n",
    "State-of-the-Art Face Recognition](https://www.cs.cmu.edu/~sbhagava/papers/face-rec-ccs16.pdf)  \n",
    "[3] [Adam: A method for stochastic optimization](https://arxiv.org/abs/1412.6980)  \n",
    "[4] [Deep Learning, S.82.86](http://www.deeplearningbook.org)  \n",
    "[5] [GTRSB](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset)  \n",
    "[6] [ImageNet-trained CNNs are biased towards texture](https://openreview.net/forum?id=Bygh9j09KX)  \n",
    "[7] [One Pixel Attack for Fooling\n",
    "Deep Neural Networks](https://arxiv.org/pdf/1710.08864.pdf)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
